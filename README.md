At the end of the experiment you will be able to :
Run Phi-2, Microsoft's small language model (SLM), using two methods:
Direct Inference using HuggingFace
Retrieval Augmented Generation (RAG) using Llama-index
Know the basic working of Llama Index VectorStore
Implement the Hugging Face embedding
Implement a simple FAISS-based vector store for efficient similarity search of high-dimensional data.
Create RetrievalQA chain along with prompt template
Compare the effectiveness of Phi-2 & Zephyr-7b-beta model by means of Cosine Similarity.
Compare the effectiveness of 5 different Hugging Face embeddings by computing and analyzing the cosine similarity
between the embedded vectors of queries and results from Zephyr-7b-beta model, to understand the differences in semantic similarity and performance.
